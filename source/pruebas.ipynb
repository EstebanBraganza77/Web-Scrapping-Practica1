{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as p\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url1 = \"https://www.plusvalia.com\"\n",
    "url2 = \"https://www.deviantart.com\"\n",
    "url3 = \"https://store.steampowered.com\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posibilidades con devianrt\n",
    "\n",
    "1. Búsqueda por palabra, por ejemplo \"sky\" (240k resultados):\n",
    "    https://www.deviantart.com/search?q=sky&cursor=MTQwYWI2MjA9NCY1OTBhY2FkMD03MiZkMTc0YjZiYz1OJTJGQSY3ODAwOTk4MiU1QjAlNUQ9NjAxNzM0MzgxJjc4MDA5OTgyJTVCMSU1RD05Njg3OTExNjYmNzgwMDk5ODIlNUIyJTVEPTg4Mzg5NTgwNCY3ODAwOTk4MiU1QjMlNUQ9ODg2NjA2Nzk4Jjc4MDA5OTgyJTVCNCU1RD02OTcxNDU0NzQ\n",
    "\n",
    "2. iterar por las páginas a partir del botón next\n",
    "\n",
    "3. de cada imagen sacar:\n",
    "    - enlace de la imagen\n",
    "    - título\n",
    "    - autor\n",
    "    - num. favoritos\n",
    "    - num. comentarios\n",
    "    - num. views\n",
    "    - tags\n",
    "    - fecha de publicación\n",
    "    - tamaño de la imagen\n",
    "\n",
    "NO necesario autenticarse\n",
    "\n",
    "4. Términos de uso: https://www.deviantart.com/about/policy/service \n",
    "    Hay sección de scraping y IAs pero no se menciona nada de limitaciones a la hora de hacer scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Posibilidades con steam\n",
    "\n",
    "1. búsqueda de juegos por género, ejemplo \"free to play\"\n",
    "    https://store.steampowered.com/genre/Free%20to%20Play/\n",
    "\n",
    "    Es necesario selenium para paginar contenido.\n",
    "\n",
    "2. de cada juego, en su página, extraer:\n",
    "    - título\n",
    "    - requisitos del sistema, mínimo y recomendado\n",
    "    - desarrollador\n",
    "    - género\n",
    "    - editor\n",
    "    - fecha de lanzamiento\n",
    "    - link al vídeo\n",
    "    - link a las imágenes\n",
    "\n",
    "3. Acuerdo de privacidad: https://store.steampowered.com/privacy_agreement/?snr=1_44_44_\n",
    "    Informacion legal: https://store.steampowered.com/legal/?snr=1_44_44_\n",
    "    Sin menciones a scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusiones**:\n",
    "Ambas se pueden scrapear y dependiendo de lo que queramos sacar puede ser más sencillo o más complejo. La de deviantart me parece una página más agradable y limpia, pero ambas me parecen buena opción. No he hecho la revisión de plusvalia.com pero, por encima, parece muy similar a idealista o fotocasa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.by import By\n",
    "import urllib.parse\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [\n",
    "    \"Fantasy art\",\n",
    "    \"Science fiction art\",\n",
    "    \"Anime and manga art\",\n",
    "    \"Fan art (for specific fandoms)\",\n",
    "    \"Digital paintings\",\n",
    "    \"Traditional drawings\",\n",
    "    \"Character designs\",\n",
    "    \"Creature concepts\",\n",
    "    \"Landscape art\",\n",
    "    \"Abstract art\",\n",
    "    \"Surrealism\",\n",
    "    \"Steampunk art\",\n",
    "    \"Cyberpunk art\",\n",
    "    \"Gothic art\",\n",
    "    \"Horror art\",\n",
    "    \"Cosplay photography\",\n",
    "    \"Pixel art\",\n",
    "    \"Concept art\",\n",
    "    \"Comics and graphic novels\",\n",
    "    \"Street art and graffiti\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import urllib.parse\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "class DeviantArtScraper: \n",
    "    def __init__(self, max_pages: int, topics: list, save_path: str):\n",
    "        self.max_pages=max_pages\n",
    "        self.topics=topics\n",
    "        self.base_url=\"https://www.deviantart.com/search\"\n",
    "        self.save_path_csv = save_path + '/images_db.csv'\n",
    "        self.save_path_json = save_path + '/images_db.json'\n",
    "        self.information= {\n",
    "            'data':[],\n",
    "            'search_topic':[],\n",
    "            'page_num':[]\n",
    "        }\n",
    "        self.error_links = []\n",
    "        self.start_driver()\n",
    "        self.user_agent = UserAgent()\n",
    "\n",
    "    def close_driver(self):\n",
    "        self.driver.close()\n",
    "\n",
    "    def start_driver(self):\n",
    "        self.driver=webdriver.Chrome()\n",
    "\n",
    "    def run_scrapper(self):\n",
    "        for topic in self.topics:\n",
    "            parsed_topic = urllib.parse.quote(topic)\n",
    "            search_url = f'{self.base_url}?q={parsed_topic}'\n",
    "            page = 0\n",
    "            while page < self.max_pages:\n",
    "                #self.driver.execute_cdp_cmd(\"Network.setUserAgentOverride\", {\"userAgent\": self.user_agent.random}) \n",
    "                #print(self.driver.execute_script(\"return navigator.userAgent;\")) \n",
    "                self.driver.get(search_url)\n",
    "                \n",
    "                # Obtenemos links de cada imagen\n",
    "                image_classes = self.driver.find_elements(By.CLASS_NAME, \"_3Y0hT\")\n",
    "                image_links = [image.find_element(By.TAG_NAME, 'a').get_attribute('href') for image in image_classes]\n",
    "                self.navigate_images_links(image_links=image_links, page=page, topic=topic)\n",
    "        \n",
    "                # Navegamos a la siguiente pagina.\n",
    "                try:\n",
    "                    next_page = self.driver.find_element(By.LINK_TEXT,'Next')\n",
    "                    search_url = next_page.get_attribute('href')\n",
    "                except Exception as e:\n",
    "                    print(f'Error al encontrar una nueva pagina {topic}, page: {page}')\n",
    "                    print(e)\n",
    "                    break\n",
    "                page += 1\n",
    "        # Ceerramos el browser\n",
    "        self.close_driver()\n",
    "        self.generate_df()\n",
    "    \n",
    "    def navigate_images_links(self, image_links: list, page:int, topic: str):\n",
    "        for link in image_links:\n",
    "            try:\n",
    "                self.information['data'].append(self.get_info_from_url(link))\n",
    "                self.information['search_topic'].append(topic)\n",
    "                self.information['page_num'].append(page)\n",
    "            except Exception as e:\n",
    "                print(f' Ha habido un error al tratar de procesar el siguiente link: {link}, pagina {page}, tema {topic}')\n",
    "                print(e)\n",
    "                self.error_links.append(link)\n",
    "\n",
    "    def generate_df(self):\n",
    "        self.df = pd.DataFrame(self.information)\n",
    "        self.df = pd.concat([self.df.loc[:,['search_topic', 'page_num']], pd.json_normalize(self.df['data'])], axis=1)\n",
    "        \n",
    "    def save_csv(self):\n",
    "        self.df.to_csv(self.save_path_csv, sep=',')\n",
    "\n",
    "    def save_json(self):\n",
    "        with open(self.save_path_json, 'w') as json_file:\n",
    "            json.dump(self.information, json_file)\n",
    "\n",
    "    def convert_views(self, metric_str: str) -> int:\n",
    "        \"\"\"\n",
    "        Converts a string of any metric field to an integer,\n",
    "        replacing 'K' for thousands or 'M' for millions.\n",
    "        \"\"\"\n",
    "        if \"K\" in metric_str:\n",
    "            return int(float(metric_str.replace(\"K\", \"\")) * 1000)\n",
    "        elif \"M\" in metric_str:\n",
    "            return int(float(metric_str.replace(\"M\", \"\")) * 1000000)\n",
    "        return int(metric_str)\n",
    "\n",
    "    def get_info_from_url(self, url: str) -> dict:\n",
    "        \"\"\"\n",
    "        Get information from a given URL.\n",
    "\n",
    "        Args:\n",
    "            url (str): The URL of the webpage from which information needs to be extracted.\n",
    "\n",
    "        Returns:\n",
    "            dict: A dictionary containing the extracted information from the webpage.\n",
    "        \"\"\"\n",
    "        with requests.Session() as session:\n",
    "            headers = {'User-Agent': self.user_agent.random}\n",
    "            try:\n",
    "                page = session.get(url, timeout=5, headers=headers)\n",
    "            except requests.exceptions.RequestException as e:\n",
    "                print(f\"An error occurred during the request: {e}\")\n",
    "                return None\n",
    "\n",
    "            if page is None or page.status_code != 200:\n",
    "                # Handle cases where the page is not retrieved successfully\n",
    "                print(\"Failed to get page\")\n",
    "                return None\n",
    "\n",
    "            soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "            # Campos principales de la imagen\n",
    "            image_url = soup.find(\"div\", class_=\"_2SlAD\").find(\"img\")[\"src\"]\n",
    "            image_title = soup.find(\"div\", class_=\"U2aSH\").text\n",
    "            image_author = soup.find(\"span\", class_=\"_12F3u\").text\n",
    "\n",
    "            # Métricas de la imagen (favs, comments, views y private_collections)\n",
    "            metrics = [metric.text for metric in soup.find_all(\"span\", class_=\"_3AClx\")]\n",
    "\n",
    "            # En algunos casos metrics devuelve varios valores para favoritos, el correcto será el último\n",
    "            image_favs = self.convert_views(\n",
    "                [metric.split(\" \")[0] for metric in metrics if \"Favourites\" in metric][-1]\n",
    "            )\n",
    "            num_comments = [\n",
    "                int(metric.split(\" \")[0]) for metric in metrics if \"Comments\" in metric\n",
    "            ][0]\n",
    "            image_views = self.convert_views(\n",
    "                [metric.split(\" \")[0] for metric in metrics if \"Views\" in metric][0]\n",
    "            )\n",
    "\n",
    "            try:\n",
    "                private_collections = [\n",
    "                    int(metric.split(\" \")[0])\n",
    "                    for metric in metrics\n",
    "                    if \"Collected Privately\" in metric\n",
    "                ][0]\n",
    "            # Si no existe este campo en metrics devuelve 0\n",
    "            except IndexError:\n",
    "                private_collections = 0\n",
    "\n",
    "            tags = [tag.text for tag in soup.find_all(\"span\", class_=\"_1nwad\")]\n",
    "\n",
    "            try:\n",
    "                description = (\n",
    "                    soup.find(\n",
    "                        \"div\", class_=\"legacy-journal _2DahR _3bG54 maturefilter _3if5g\"\n",
    "                    )\n",
    "                    .get_text(separator=\" \", strip=True)\n",
    "                    .replace(\"\\xa0\", \"\\n\")\n",
    "                )\n",
    "            except AttributeError:\n",
    "                description = None\n",
    "\n",
    "            try:\n",
    "                location = soup.find(\"div\", class_=\"_3FMM3\").text.split(\"\\xa0\")[-1]\n",
    "            except AttributeError:\n",
    "                location = None\n",
    "\n",
    "            image_px = soup.find(\"div\", class_=\"_3RVC5\").next_sibling.text.split(\"px\")[0]\n",
    "            image_size_mb = float(\n",
    "                soup.find(\"div\", class_=\"_3RVC5\")\n",
    "                .next_sibling.text.split(\"px\")[1]\n",
    "                .strip()\n",
    "                .split(\" \")[0]\n",
    "            )\n",
    "\n",
    "            published_date = soup.find(\"div\", class_=\"_1mcmq\").find(\"time\")[\"datetime\"]\n",
    "\n",
    "            if num_comments > 0:\n",
    "                try:\n",
    "                    last_comment = (soup.find(\"span\", class_=\"_2PHJq\").text).strip()\n",
    "                except:\n",
    "                    last_comment = \"\"\n",
    "\n",
    "            results = {\n",
    "                \"image_url\": image_url,\n",
    "                \"image_title\": image_title,\n",
    "                \"image_author\": image_author,\n",
    "                \"image_favs\": image_favs,\n",
    "                \"image_com\": num_comments,\n",
    "                \"image_views\": image_views,\n",
    "                \"private_collections\": private_collections,\n",
    "                \"tags\": tags,\n",
    "                \"location\": location,\n",
    "                \"description\": description,\n",
    "                \"image_px\": image_px,\n",
    "                \"image_size\": image_size_mb,\n",
    "                \"published_date\": published_date,\n",
    "                \"last_comment\": last_comment,\n",
    "            }\n",
    "\n",
    "        return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [\"Street art and graffiti\", 'sky']\n",
    "scraper = DeviantArtScraper(max_pages = 2, topics=topics, save_path = './dataset')\n",
    "#scraper.run_scrapper() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1 Favourite', '0 Comments', '163 Views']\n",
      "1\n",
      "0\n",
      "163\n"
     ]
    }
   ],
   "source": [
    "#scraper.get_info_from_url('https://www.deviantart.com/psktear/art/blue-46653661')\n",
    "\n",
    "user_agent = UserAgent()\n",
    "\n",
    "headers = {'User-Agent': user_agent.random}\n",
    "session = requests.Session()\n",
    "response = session.get('https://www.deviantart.com/coolarts223/art/Colorful-Street-Art-at-Night-1009044894')\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "soup.find(\"div\", class_=\"U2aSH\").text\n",
    "soup.find(\"span\", class_=\"_12F3u\").text\n",
    "metrics = [metric.text for metric in soup.find_all(\"span\", class_=\"_3AClx\")]\n",
    "image_favs = [metric.split(\" \")[0] for metric in metrics if \"Favourites\" in metric or  \"Favourite\" in metric][-1] \n",
    "num_comments = [int(metric.split(\" \")[0]) for metric in metrics if \"Comments\" in metric or \"Comment\" in metric][0]\n",
    "image_views = [metric.split(\" \")[0] for metric in metrics if \"Views\" in metric or \"View\" in metric][0]\n",
    "    \n",
    "print(metrics)\n",
    "print(image_favs)\n",
    "print(num_comments)\n",
    "print(image_views)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 120\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mfloat\u001b[39m(metric_str\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000000\u001b[39m)\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mint\u001b[39m(metric_str)\n\u001b[1;32m--> 120\u001b[0m \u001b[43mget_info_from_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://www.deviantart.com/coolarts223/art/Colorful-Street-Art-at-Night-1009044894\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[55], line 36\u001b[0m, in \u001b[0;36mget_info_from_url\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     32\u001b[0m metrics \u001b[38;5;241m=\u001b[39m [metric\u001b[38;5;241m.\u001b[39mtext \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspan\u001b[39m\u001b[38;5;124m\"\u001b[39m, class_\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_3AClx\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# En algunos casos metrics devuelve varios valores para favoritos, el correcto será el último\u001b[39;00m\n\u001b[0;32m     35\u001b[0m image_favs \u001b[38;5;241m=\u001b[39m convert_views(\n\u001b[1;32m---> 36\u001b[0m     \u001b[43m[\u001b[49m\u001b[43mmetric\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFavourites\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     37\u001b[0m )\n\u001b[0;32m     38\u001b[0m num_comments \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28mint\u001b[39m(metric\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m metrics \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComments\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m metric\n\u001b[0;32m     40\u001b[0m ][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     41\u001b[0m image_views \u001b[38;5;241m=\u001b[39m convert_views(\n\u001b[0;32m     42\u001b[0m     [metric\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m metrics \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mViews\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m metric][\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     43\u001b[0m )\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def get_info_from_url(url: str) -> dict:\n",
    "    \"\"\"\n",
    "    Get information from a given URL.\n",
    "\n",
    "    Args:\n",
    "        url (str): The URL of the webpage from which information needs to be extracted.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the extracted information from the webpage.\n",
    "    \"\"\"\n",
    "    with requests.Session() as session:\n",
    "        #headers = {'User-Agent': user_agent.random}\n",
    "        try:\n",
    "            page = session.get(url, timeout=5)\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"An error occurred during the request: {e}\")\n",
    "            return None\n",
    "\n",
    "        if page is None or page.status_code != 200:\n",
    "            # Handle cases where the page is not retrieved successfully\n",
    "            print(\"Failed to get page\")\n",
    "            return None\n",
    "\n",
    "        soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "        # Campos principales de la imagen\n",
    "        image_url = soup.find(\"div\", class_=\"_2SlAD\").find(\"img\")[\"src\"]\n",
    "        image_title = soup.find(\"div\", class_=\"U2aSH\").text\n",
    "        image_author = soup.find(\"span\", class_=\"_12F3u\").text\n",
    "\n",
    "        # Métricas de la imagen (favs, comments, views y private_collections)\n",
    "        metrics = [metric.text for metric in soup.find_all(\"span\", class_=\"_3AClx\")]\n",
    "\n",
    "        # En algunos casos metrics devuelve varios valores para favoritos, el correcto será el último\n",
    "        image_favs = convert_views(\n",
    "            [metric.split(\" \")[0] for metric in metrics if \"Favourites\" in metric or \"Favourite\" in metric][-1]\n",
    "        )\n",
    "        num_comments = [\n",
    "            int(metric.split(\" \")[0]) for metric in metrics if \"Comments\" in metric or \"Comment\" in metric\n",
    "        ][0]\n",
    "        image_views = convert_views(\n",
    "            [metric.split(\" \")[0] for metric in metrics if \"Views\" in metric or \"View\" in metric][0]\n",
    "        )\n",
    "\n",
    "        try:\n",
    "            private_collections = [\n",
    "                int(metric.split(\" \")[0])\n",
    "                for metric in metrics\n",
    "                if \"Collected Privately\" in metric\n",
    "            ][0]\n",
    "        # Si no existe este campo en metrics devuelve 0\n",
    "        except IndexError:\n",
    "            private_collections = 0\n",
    "\n",
    "        tags = [tag.text for tag in soup.find_all(\"span\", class_=\"_1nwad\")]\n",
    "\n",
    "        try:\n",
    "            description = (\n",
    "                soup.find(\n",
    "                    \"div\", class_=\"legacy-journal _2DahR _3bG54 maturefilter _3if5g\"\n",
    "                )\n",
    "                .get_text(separator=\" \", strip=True)\n",
    "                .replace(\"\\xa0\", \"\\n\")\n",
    "            )\n",
    "        except AttributeError:\n",
    "            description = None\n",
    "\n",
    "        try:\n",
    "            location = soup.find(\"div\", class_=\"_3FMM3\").text.split(\"\\xa0\")[-1]\n",
    "        except AttributeError:\n",
    "            location = None\n",
    "\n",
    "        image_px = soup.find(\"div\", class_=\"_3RVC5\").next_sibling.text.split(\"px\")[0]\n",
    "        image_size_mb = float(\n",
    "            soup.find(\"div\", class_=\"_3RVC5\")\n",
    "            .next_sibling.text.split(\"px\")[1]\n",
    "            .strip()\n",
    "            .split(\" \")[0]\n",
    "        )\n",
    "\n",
    "        published_date = soup.find(\"div\", class_=\"_1mcmq\").find(\"time\")[\"datetime\"]\n",
    "\n",
    "        if num_comments > 0:\n",
    "            try:\n",
    "                last_comment = (soup.find(\"span\", class_=\"_2PHJq\").text).strip()\n",
    "            except:\n",
    "                last_comment = \"\"\n",
    "\n",
    "        results = {\n",
    "            \"image_url\": image_url,\n",
    "            \"image_title\": image_title,\n",
    "            \"image_author\": image_author,\n",
    "            \"image_favs\": image_favs,\n",
    "            \"image_com\": num_comments,\n",
    "            \"image_views\": image_views,\n",
    "            \"private_collections\": private_collections,\n",
    "            \"tags\": tags,\n",
    "            \"location\": location,\n",
    "            \"description\": description,\n",
    "            \"image_px\": image_px,\n",
    "            \"image_size\": image_size_mb,\n",
    "            \"published_date\": published_date,\n",
    "            \"last_comment\": last_comment,\n",
    "        }\n",
    "\n",
    "    return results\n",
    "\n",
    "def convert_views(metric_str: str) -> int:\n",
    "    \"\"\"\n",
    "    Converts a string of any metric field to an integer,\n",
    "    replacing 'K' for thousands or 'M' for millions.\n",
    "    \"\"\"\n",
    "    if \"K\" in metric_str:\n",
    "        return int(float(metric_str.replace(\"K\", \"\")) * 1000)\n",
    "    elif \"M\" in metric_str:\n",
    "        return int(float(metric_str.replace(\"M\", \"\")) * 1000000)\n",
    "    return int(metric_str)\n",
    "\n",
    "\n",
    "get_info_from_url(url='https://www.deviantart.com/coolarts223/art/Colorful-Street-Art-at-Night-1009044894')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image_url': 'https://images-wixmp-ed30a86b8c4ca887773594c2.wixmp.com/f/b3be1dae-3caa-4d45-be6c-3de586ba95e2/dekxdig-c4062bb4-8152-43ca-93a6-6f4a5afa2935.jpg?token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJ1cm46YXBwOjdlMGQxODg5ODIyNjQzNzNhNWYwZDQxNWVhMGQyNmUwIiwiaXNzIjoidXJuOmFwcDo3ZTBkMTg4OTgyMjY0MzczYTVmMGQ0MTVlYTBkMjZlMCIsIm9iaiI6W1t7InBhdGgiOiJcL2ZcL2IzYmUxZGFlLTNjYWEtNGQ0NS1iZTZjLTNkZTU4NmJhOTVlMlwvZGVreGRpZy1jNDA2MmJiNC04MTUyLTQzY2EtOTNhNi02ZjRhNWFmYTI5MzUuanBnIn1dXSwiYXVkIjpbInVybjpzZXJ2aWNlOmZpbGUuZG93bmxvYWQiXX0.2oOfqnCn_Jt7WjX1je45XxrWrT9334AxXWuWbu0ww-8',\n",
       " 'image_title': 'Photography Session',\n",
       " 'image_author': 'BisBiswas',\n",
       " 'image_favs': 1600,\n",
       " 'image_com': 57,\n",
       " 'image_views': 720400,\n",
       " 'private_collections': 1,\n",
       " 'tags': ['blue',\n",
       "  'camera',\n",
       "  'duck',\n",
       "  'man',\n",
       "  'sky',\n",
       "  'art',\n",
       "  'aesthetic',\n",
       "  'afternoon',\n",
       "  'alone',\n",
       "  'animals',\n",
       "  'artwork',\n",
       "  'beautiful',\n",
       "  'clouds',\n",
       "  'darkart',\n",
       "  'darkness',\n",
       "  'digitalart',\n",
       "  'digitaldrawing',\n",
       "  'digitalpainting',\n",
       "  'drawing',\n",
       "  'evening',\n",
       "  'illustration',\n",
       "  'lake',\n",
       "  'landscape',\n",
       "  'nature',\n",
       "  'painting',\n",
       "  'photography',\n",
       "  'photoshoot',\n",
       "  'scenery',\n",
       "  'sunset',\n",
       "  'wallpaper'],\n",
       " 'location': None,\n",
       " 'description': 'Instagram 👉🏿 www.instagram.com/hereisbis/',\n",
       " 'image_px': '1920x1080',\n",
       " 'image_size': 318.04,\n",
       " 'published_date': '2021-06-04T22:38:18.000Z',\n",
       " 'last_comment': '💕'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scraper.information['data'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraper.generate_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_topic</th>\n",
       "      <th>page_num</th>\n",
       "      <th>image_url</th>\n",
       "      <th>image_title</th>\n",
       "      <th>image_author</th>\n",
       "      <th>image_favs</th>\n",
       "      <th>image_com</th>\n",
       "      <th>image_views</th>\n",
       "      <th>private_collections</th>\n",
       "      <th>tags</th>\n",
       "      <th>location</th>\n",
       "      <th>description</th>\n",
       "      <th>image_px</th>\n",
       "      <th>image_size</th>\n",
       "      <th>published_date</th>\n",
       "      <th>last_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sky</td>\n",
       "      <td>0</td>\n",
       "      <td>https://images-wixmp-ed30a86b8c4ca887773594c2....</td>\n",
       "      <td>Photography Session</td>\n",
       "      <td>BisBiswas</td>\n",
       "      <td>1600</td>\n",
       "      <td>57</td>\n",
       "      <td>720400</td>\n",
       "      <td>1</td>\n",
       "      <td>[blue, camera, duck, man, sky, art, aesthetic,...</td>\n",
       "      <td>None</td>\n",
       "      <td>Instagram 👉🏿 www.instagram.com/hereisbis/</td>\n",
       "      <td>1920x1080</td>\n",
       "      <td>318.04</td>\n",
       "      <td>2021-06-04T22:38:18.000Z</td>\n",
       "      <td>💕</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sky</td>\n",
       "      <td>0</td>\n",
       "      <td>https://images-wixmp-ed30a86b8c4ca887773594c2....</td>\n",
       "      <td>Sky Temple</td>\n",
       "      <td>AlynSpiller</td>\n",
       "      <td>2900</td>\n",
       "      <td>56</td>\n",
       "      <td>146600</td>\n",
       "      <td>0</td>\n",
       "      <td>[bigsun, asian, clouds, conceptart, digitalart...</td>\n",
       "      <td>None</td>\n",
       "      <td>Thanks for looking! instagram YouTube Facebook</td>\n",
       "      <td>912x1200</td>\n",
       "      <td>867.98</td>\n",
       "      <td>2017-06-09T18:03:29.000Z</td>\n",
       "      <td>Lovely.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sky</td>\n",
       "      <td>0</td>\n",
       "      <td>https://images-wixmp-ed30a86b8c4ca887773594c2....</td>\n",
       "      <td>Sky Breaker</td>\n",
       "      <td>aerroscape</td>\n",
       "      <td>2500</td>\n",
       "      <td>95</td>\n",
       "      <td>64800</td>\n",
       "      <td>0</td>\n",
       "      <td>[breaker, clouds, digital, landscape, sky, sto...</td>\n",
       "      <td>None</td>\n",
       "      <td>the water cycle ...like you learned in geograp...</td>\n",
       "      <td>7045x4981</td>\n",
       "      <td>15.47</td>\n",
       "      <td>2015-11-19T22:48:01.000Z</td>\n",
       "      <td>Pretty!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sky</td>\n",
       "      <td>0</td>\n",
       "      <td>https://images-wixmp-ed30a86b8c4ca887773594c2....</td>\n",
       "      <td>Sky for Dreamers</td>\n",
       "      <td>RHADS</td>\n",
       "      <td>12400</td>\n",
       "      <td>393</td>\n",
       "      <td>328500</td>\n",
       "      <td>0</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>Recommended music: Duran Duran - Ordinary Worl...</td>\n",
       "      <td>3200x2400</td>\n",
       "      <td>1.13</td>\n",
       "      <td>2013-08-02T17:40:43.000Z</td>\n",
       "      <td>I really like this kind of landscape comics, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sky</td>\n",
       "      <td>0</td>\n",
       "      <td>https://images-wixmp-ed30a86b8c4ca887773594c2....</td>\n",
       "      <td>Divine Sky</td>\n",
       "      <td>BisBiswas</td>\n",
       "      <td>2100</td>\n",
       "      <td>85</td>\n",
       "      <td>459000</td>\n",
       "      <td>3</td>\n",
       "      <td>[black, blue, devine, god, man, sky, art, aest...</td>\n",
       "      <td>None</td>\n",
       "      <td>Instagram 👉🏿 www.instagram.com/hereisbis/</td>\n",
       "      <td>3840x2160</td>\n",
       "      <td>2.76</td>\n",
       "      <td>2022-02-02T22:40:28.000Z</td>\n",
       "      <td>This Art is stuning!! the sky is amazing!!! lo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  search_topic  page_num                                          image_url  \\\n",
       "0          sky         0  https://images-wixmp-ed30a86b8c4ca887773594c2....   \n",
       "1          sky         0  https://images-wixmp-ed30a86b8c4ca887773594c2....   \n",
       "2          sky         0  https://images-wixmp-ed30a86b8c4ca887773594c2....   \n",
       "3          sky         0  https://images-wixmp-ed30a86b8c4ca887773594c2....   \n",
       "4          sky         0  https://images-wixmp-ed30a86b8c4ca887773594c2....   \n",
       "\n",
       "           image_title image_author  image_favs  image_com  image_views  \\\n",
       "0  Photography Session    BisBiswas        1600         57       720400   \n",
       "1           Sky Temple  AlynSpiller        2900         56       146600   \n",
       "2          Sky Breaker   aerroscape        2500         95        64800   \n",
       "3     Sky for Dreamers        RHADS       12400        393       328500   \n",
       "4           Divine Sky    BisBiswas        2100         85       459000   \n",
       "\n",
       "   private_collections                                               tags  \\\n",
       "0                    1  [blue, camera, duck, man, sky, art, aesthetic,...   \n",
       "1                    0  [bigsun, asian, clouds, conceptart, digitalart...   \n",
       "2                    0  [breaker, clouds, digital, landscape, sky, sto...   \n",
       "3                    0                                                 []   \n",
       "4                    3  [black, blue, devine, god, man, sky, art, aest...   \n",
       "\n",
       "  location                                        description   image_px  \\\n",
       "0     None          Instagram 👉🏿 www.instagram.com/hereisbis/  1920x1080   \n",
       "1     None     Thanks for looking! instagram YouTube Facebook   912x1200   \n",
       "2     None  the water cycle ...like you learned in geograp...  7045x4981   \n",
       "3     None  Recommended music: Duran Duran - Ordinary Worl...  3200x2400   \n",
       "4     None          Instagram 👉🏿 www.instagram.com/hereisbis/  3840x2160   \n",
       "\n",
       "   image_size            published_date  \\\n",
       "0      318.04  2021-06-04T22:38:18.000Z   \n",
       "1      867.98  2017-06-09T18:03:29.000Z   \n",
       "2       15.47  2015-11-19T22:48:01.000Z   \n",
       "3        1.13  2013-08-02T17:40:43.000Z   \n",
       "4        2.76  2022-02-02T22:40:28.000Z   \n",
       "\n",
       "                                        last_comment  \n",
       "0                                                  💕  \n",
       "1                                            Lovely.  \n",
       "2                                            Pretty!  \n",
       "3  I really like this kind of landscape comics, l...  \n",
       "4  This Art is stuning!! the sky is amazing!!! lo...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Ejemplo de data frame resultante.\n",
    "scraper.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Optional\n",
    "import requests\n",
    "\n",
    "def download_image(\n",
    "    url_image: str, images_folder: Optional[str] = \"./deviantart_images\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Function to download images from url.\n",
    "    \"\"\"\n",
    "    # Crea el directorio si no existe\n",
    "    if not os.path.exists(images_folder):\n",
    "        os.makedirs(images_folder)\n",
    "\n",
    "    image_title = url_image.split(\"?\")[0].split(\"/\")[-1]\n",
    "    response = requests.get(url_image, stream=True)\n",
    "    if response.status_code == 200:\n",
    "        with open(f\"{images_folder}/{image_title}\", \"wb\") as out_file:\n",
    "            out_file.write(response.content)\n",
    "    del response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_url = \"https://images-wixmp-ed30a86b8c4ca887773594c2.wixmp.com/f/0a843e25-2d15-4be3-89b7-0988b20ba533/dgxans7-5ae719f2-1827-4f45-bf4e-35d6ed29c13e.png/v1/fill/w_1192,h_670,q_70,strp/infinite_love_by_mumu0909_dgxans7-pre.jpg?token=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJ1cm46YXBwOjdlMGQxODg5ODIyNjQzNzNhNWYwZDQxNWVhMGQyNmUwIiwiaXNzIjoidXJuOmFwcDo3ZTBkMTg4OTgyMjY0MzczYTVmMGQ0MTVlYTBkMjZlMCIsIm9iaiI6W1t7ImhlaWdodCI6Ijw9MTA4MCIsInBhdGgiOiJcL2ZcLzBhODQzZTI1LTJkMTUtNGJlMy04OWI3LTA5ODhiMjBiYTUzM1wvZGd4YW5zNy01YWU3MTlmMi0xODI3LTRmNDUtYmY0ZS0zNWQ2ZWQyOWMxM2UucG5nIiwid2lkdGgiOiI8PTE5MjAifV1dLCJhdWQiOlsidXJuOnNlcnZpY2U6aW1hZ2Uub3BlcmF0aW9ucyJdfQ.w9ViEdqc7o6LD0D1u0Ze1ycczCudKRbxVS-VLcnq4Ts\"\n",
    "download_image(image_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>search_topic</th>\n",
       "      <th>page_num</th>\n",
       "      <th>image_url</th>\n",
       "      <th>image_title</th>\n",
       "      <th>image_author</th>\n",
       "      <th>image_favs</th>\n",
       "      <th>image_com</th>\n",
       "      <th>image_views</th>\n",
       "      <th>private_collections</th>\n",
       "      <th>tags</th>\n",
       "      <th>location</th>\n",
       "      <th>description</th>\n",
       "      <th>image_px</th>\n",
       "      <th>image_size</th>\n",
       "      <th>published_date</th>\n",
       "      <th>last_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6570</th>\n",
       "      <td>Street art and graffiti</td>\n",
       "      <td>14</td>\n",
       "      <td>https://images-wixmp-ed30a86b8c4ca887773594c2....</td>\n",
       "      <td>Ethel</td>\n",
       "      <td>WhoAm-Irony</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['coloured', 'die', 'graffiti', 'hair', 'liver...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>My new piece in Liverpool, UK. Model Anna Ance...</td>\n",
       "      <td>6016x4000</td>\n",
       "      <td>10.21</td>\n",
       "      <td>2015-02-22T15:48:58.000Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6571</th>\n",
       "      <td>Street art and graffiti</td>\n",
       "      <td>14</td>\n",
       "      <td>https://images-wixmp-ed30a86b8c4ca887773594c2....</td>\n",
       "      <td>Urban Elegy - Mobile Wallpaper</td>\n",
       "      <td>EdenAgency</td>\n",
       "      <td>40.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>19500.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['digitalart', 'digitalillustration', 'digital...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Step into the haunting beauty of \"Urban Elegy,...</td>\n",
       "      <td>1024x1792</td>\n",
       "      <td>2.86</td>\n",
       "      <td>2024-01-17T08:20:46.000Z</td>\n",
       "      <td>All I can say is, \"Wow, AI!\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6572</th>\n",
       "      <td>Street art and graffiti</td>\n",
       "      <td>14</td>\n",
       "      <td>https://images-wixmp-ed30a86b8c4ca887773594c2....</td>\n",
       "      <td>Street Art</td>\n",
       "      <td>gnuman12</td>\n",
       "      <td>27.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['ai', 'colorful', 'girl', 'highres', 'cellpho...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5504x3456</td>\n",
       "      <td>24.27</td>\n",
       "      <td>2023-09-17T00:29:55.000Z</td>\n",
       "      <td>Saw it this morning on my cell phone and I did...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6573</th>\n",
       "      <td>Street art and graffiti</td>\n",
       "      <td>14</td>\n",
       "      <td>https://images-wixmp-ed30a86b8c4ca887773594c2....</td>\n",
       "      <td>Graffiti 3204</td>\n",
       "      <td>cmdpirxII</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1800.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['aerosol', 'artist', 'bombing', 'can', 'chara...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I only took the photo !! I have no claim to th...</td>\n",
       "      <td>1600x941</td>\n",
       "      <td>854.90</td>\n",
       "      <td>2014-10-16T20:33:12.000Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6574</th>\n",
       "      <td>Street art and graffiti</td>\n",
       "      <td>14</td>\n",
       "      <td>https://images-wixmp-ed30a86b8c4ca887773594c2....</td>\n",
       "      <td>RADICALS CREW</td>\n",
       "      <td>imagophil</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['graffiti', 'graffitiart', 'urban', 'urbexpho...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>street art gallery</td>\n",
       "      <td>2131x1795</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2022-10-23T18:27:21.000Z</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 search_topic  page_num  \\\n",
       "6570  Street art and graffiti        14   \n",
       "6571  Street art and graffiti        14   \n",
       "6572  Street art and graffiti        14   \n",
       "6573  Street art and graffiti        14   \n",
       "6574  Street art and graffiti        14   \n",
       "\n",
       "                                              image_url  \\\n",
       "6570  https://images-wixmp-ed30a86b8c4ca887773594c2....   \n",
       "6571  https://images-wixmp-ed30a86b8c4ca887773594c2....   \n",
       "6572  https://images-wixmp-ed30a86b8c4ca887773594c2....   \n",
       "6573  https://images-wixmp-ed30a86b8c4ca887773594c2....   \n",
       "6574  https://images-wixmp-ed30a86b8c4ca887773594c2....   \n",
       "\n",
       "                         image_title image_author  image_favs  image_com  \\\n",
       "6570                           Ethel  WhoAm-Irony        52.0        6.0   \n",
       "6571  Urban Elegy - Mobile Wallpaper   EdenAgency        40.0        3.0   \n",
       "6572                      Street Art     gnuman12        27.0        2.0   \n",
       "6573                   Graffiti 3204    cmdpirxII        15.0        0.0   \n",
       "6574                   RADICALS CREW    imagophil        10.0        0.0   \n",
       "\n",
       "      image_views  private_collections  \\\n",
       "6570       1500.0                  0.0   \n",
       "6571      19500.0                  0.0   \n",
       "6572       1600.0                  0.0   \n",
       "6573       1800.0                  0.0   \n",
       "6574        620.0                  0.0   \n",
       "\n",
       "                                                   tags location  \\\n",
       "6570  ['coloured', 'die', 'graffiti', 'hair', 'liver...      NaN   \n",
       "6571  ['digitalart', 'digitalillustration', 'digital...      NaN   \n",
       "6572  ['ai', 'colorful', 'girl', 'highres', 'cellpho...      NaN   \n",
       "6573  ['aerosol', 'artist', 'bombing', 'can', 'chara...      NaN   \n",
       "6574  ['graffiti', 'graffitiart', 'urban', 'urbexpho...      NaN   \n",
       "\n",
       "                                            description   image_px  \\\n",
       "6570  My new piece in Liverpool, UK. Model Anna Ance...  6016x4000   \n",
       "6571  Step into the haunting beauty of \"Urban Elegy,...  1024x1792   \n",
       "6572                                                NaN  5504x3456   \n",
       "6573  I only took the photo !! I have no claim to th...   1600x941   \n",
       "6574                                 street art gallery  2131x1795   \n",
       "\n",
       "      image_size            published_date  \\\n",
       "6570       10.21  2015-02-22T15:48:58.000Z   \n",
       "6571        2.86  2024-01-17T08:20:46.000Z   \n",
       "6572       24.27  2023-09-17T00:29:55.000Z   \n",
       "6573      854.90  2014-10-16T20:33:12.000Z   \n",
       "6574        2.80  2022-10-23T18:27:21.000Z   \n",
       "\n",
       "                                           last_comment  \n",
       "6570                                                NaN  \n",
       "6571                       All I can say is, \"Wow, AI!\"  \n",
       "6572  Saw it this morning on my cell phone and I did...  \n",
       "6573                                                NaN  \n",
       "6574                                                NaN  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('C:/Users/esteb/OneDrive/Escritorio/Cursos y Materias/UOC Master Ciencia de Datos/Web-Scrapping-Practica1-/dataset/images_db.csv', index_col=0, sep=',')\n",
    "data.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
